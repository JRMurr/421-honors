{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmurray/anaconda/envs/421/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 23\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                      sentence1  \\\n",
       "0   5.00                         A plane is taking off.   \n",
       "1   3.80                A man is playing a large flute.   \n",
       "2   3.80  A man is spreading shreded cheese on a pizza.   \n",
       "3   2.60                   Three men are playing chess.   \n",
       "4   4.25                    A man is playing the cello.   \n",
       "\n",
       "                                           sentence2  \n",
       "0                        An air plane is taking off.  \n",
       "1                          A man is playing a flute.  \n",
       "2  A man is spreading shredded cheese on an uncoo...  \n",
       "3                         Two men are playing chess.  \n",
       "4                 A man seated is playing the cello.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, dev, test = load_data.load_sts()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to tokeinze all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000 #number of words to act as features\n",
    "maxlen = 20 #maxium length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.unique(np.append(train[\"sentence1\"].values, train[\"sentence2\"].values))\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 2064 words\n"
     ]
    }
   ],
   "source": [
    "num_words_found = len(tokenizer.word_counts)\n",
    "print('skipping {} words'.format(num_words_found - max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_df(df):\n",
    "    pad = preprocessing.sequence.pad_sequences\n",
    "    x1 =  pad(tokenizer.texts_to_sequences(df['sentence1']), maxlen=maxlen)\n",
    "    x2 =  pad(tokenizer.texts_to_sequences(df['sentence2']), maxlen=maxlen)\n",
    "    return x1,x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x1, train_x2), (dev_x1, dev_x2), (test_x1, test_x2) = tuple(map(lambda x: tokenize_df(x), [train, dev, test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we build a base model to be shared btwn the two input sentences so they both are encodded the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network():\n",
    "    \"\"\" Base network to be shared (eq. to feature extraction).\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 64, input_length=maxlen))\n",
    "    model.add(LSTM(64))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = create_base_network()\n",
    "in1 = Input(shape=(20,))\n",
    "in2 = Input(shape=(20,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we share the base layer and combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_1 = base(in1)\n",
    "encoded_2 = base(in2)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_1, encoded_2], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has no activation so it can output any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(1)(concatenated)\n",
    "model = Model(inputs=[in1, in2], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add callbacks to stop training when it doesnt get better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_mean_absolute_error',\n",
    "        patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='my_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5749 samples, validate on 1500 samples\n",
      "Epoch 1/10\n",
      "5749/5749 [==============================] - 4s 781us/step - loss: 0.0876 - mean_squared_error: 0.0876 - val_loss: 3.5987 - val_mean_squared_error: 3.5987\n",
      "Epoch 2/10\n",
      " 224/5749 [>.............................] - ETA: 4s - loss: 0.0408 - mean_squared_error: 0.0408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmurray/anaconda/envs/421/lib/python3.6/site-packages/keras/callbacks.py:526: RuntimeWarning: Early stopping conditioned on metric `val_mean_absolute_error` which is not available. Available metrics are: val_loss,val_mean_squared_error,loss,mean_squared_error\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3264/5749 [================>.............] - ETA: 1s - loss: 0.0808 - mean_squared_error: 0.0808"
     ]
    }
   ],
   "source": [
    "model.fit([train_x1, train_x2], train['score'], epochs=10,\n",
    "            batch_size=32,\n",
    "            callbacks=callbacks_list,\n",
    "            validation_data=([dev_x1, dev_x2], dev['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379/1379 [==============================] - 0s 142us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.055799792692919, 3.055799792692919]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=[test_x1, test_x2], y=test['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_squared_error']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
